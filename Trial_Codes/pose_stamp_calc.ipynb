{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import rospy\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from sensor_msgs.msg import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_with_coordinates = {'5': (406, 46), '3': (406, 407), '8': (165, 407), '1': (167, 45)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(406, 46), (406, 407), (165, 407), (167, 45)]\n",
      "['5', '3', '8', '1']\n"
     ]
    }
   ],
   "source": [
    "def extract_points(dictionary):\n",
    "    points = []\n",
    "    labels = []\n",
    "    for key, value in dictionary.items():\n",
    "        points.append(value)\n",
    "        labels.append(key)\n",
    "    return points , labels\n",
    "\n",
    "# Example usage:\n",
    "points , labels = extract_points(label_with_coordinates)\n",
    "print(points)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "   \n",
    "    rospy.init_node('depth_point_extraction', anonymous=True)\n",
    "    rospy.Subscriber('/3d_image/image_raw_depth', Image, depth_image_callback)\n",
    "    rospy.spin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def depth_image_callback(msg):\n",
    "    try:\n",
    "        # Convert ROS Image message to OpenCV image\n",
    "        bridge = CvBridge()\n",
    "        depth_image = bridge.imgmsg_to_cv2(msg, desired_encoding=\"passthrough\")\n",
    "        \n",
    "        # Convert the depth image to a Numpy array\n",
    "        depth_array = np.array(depth_image, dtype=np.float32)\n",
    "        \n",
    "        # Extract depth at the specified point\n",
    "        depth_at_point = depth_array[point_y_pixels, point_x_pixels]\n",
    "        point_z = depth_at_point\n",
    "        rospy.loginfo(\"Depth at point (%d, %d): %.2f meters\", point_x_pixels, point_y_pixels, depth_at_point)\n",
    "        print('point Z',point_z)\n",
    "\n",
    "        obj_x_m ,obj_y_m,obj_z_m  = get_x_y(point_z)\n",
    "        get_orientation_from_xyz(obj_x_m , obj_y_m , obj_z_m)\n",
    "    except CvBridgeError as e:\n",
    "        rospy.logerr(\"CvBridge Error: %s\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_x_y(depth):\n",
    "    \n",
    "    fx = 525.0  # focal length in pixels\n",
    "    fy = 525.0\n",
    "    cx = 320.0  # principal point in pixels\n",
    "    cy = 240.0\n",
    "    # centers would get from the bounding box\n",
    "    object_x_meters = (point_x_pixels - cx)*depth / fx\n",
    "    object_y_meters = (point_y_pixels - cy)*depth / fy\n",
    "    print ('Center point x & y in meters' , (object_x_meters , object_y_meters))\n",
    "    #cx cy fx fy from camera calibration\n",
    "    return object_x_meters , object_y_meters , depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_orientation_from_xyz(objX, objY, objZ):\n",
    "    # Normalize the object's position vector\n",
    "    norm = np.linalg.norm([objX, objY, objZ])\n",
    "    objX /= norm\n",
    "    objY /= norm\n",
    "    objZ /= norm\n",
    "    \n",
    "    # Define camera frame axes\n",
    "    camera_x = [1, 0, 0]\n",
    "    camera_y = [0, 1, 0]\n",
    "    camera_z = [0, 0, 1]\n",
    "\n",
    "    # Calculate the dot products between the camera frame axes and the object's position vector\n",
    "    dot_x = np.dot(camera_x, [objX, objY, objZ])\n",
    "    dot_y = np.dot(camera_y, [objX, objY, objZ])\n",
    "    dot_z = np.dot(camera_z, [objX, objY, objZ])\n",
    "\n",
    "    # Construct the rotation matrix\n",
    "    rotation_matrix = np.array([[dot_x, dot_y, dot_z],\n",
    "                                 [0, 0, 0],\n",
    "                                 [0, 0, 0]])\n",
    "\n",
    "    # Calculate the quaternion from the rotation matrix\n",
    "    qw = np.sqrt(1 + rotation_matrix[0, 0] + rotation_matrix[1, 1] + rotation_matrix[2, 2]) / 2\n",
    "    qx = (rotation_matrix[2, 1] - rotation_matrix[1, 2]) / (4 * qw)\n",
    "    qy = (rotation_matrix[0, 2] - rotation_matrix[2, 0]) / (4 * qw)\n",
    "    qz = (rotation_matrix[1, 0] - rotation_matrix[0, 1]) / (4 * qw)\n",
    "\n",
    "    pose = [qx , qy , qz , qw]\n",
    "   \n",
    "    print([qx , qy , qz , qw])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
